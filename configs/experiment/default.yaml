ckpt_path: null
ckpt_cfg_override: false
use_wandb: True
wandb:
  name: baseline
  project: grappa
  save_code: True
  tags: []
checkpointer:
  dirpath: ckpt/${experiment.wandb.project}/${experiment.wandb.name}/${now:%Y-%m-%d}_${now:%H-%M-%S-%f}
  monitor: early_stopping_loss
  mode: min
  save_top_k: 1
  save_last: True
  every_n_epochs: 5
  auto_insert_metric_name: False
  filename: 'epoch:{epoch}-early_stop_loss:{early_stopping_loss:.2f}'
progress_bar: true
trainer:
  overfit_batches: 0
  min_epochs: 5
  max_epochs: 1000
  accelerator: gpu
  log_every_n_steps: 10
  deterministic: False
  check_val_every_n_epoch: 1
evaluation:
  n_bootstrap: 1
train:
  lr: 1e-05
  energy_weight: 1.0
  gradient_weight: 0.8
  start_qm_epochs: 1
  param_loss_epochs: 10
  warmup_steps: 500
  early_stopping_energy_weight: 3.0
  param_weight: 0.001
  proper_regularisation: 1.
  improper_regularisation: 1.
  weight_decay: 0
  patience: -1
  lr_decay: 1.
  tuplewise_weight: 0.
  time_limit: 47.5
  reset_optimizer_on_load: False
  add_noise_on_load: 0.